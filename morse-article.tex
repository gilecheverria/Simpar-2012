\documentclass{llncs}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{url}
\usepackage{listings}
\usepackage{authblk}
\usepackage[pdftex]{hyperref}
\usepackage{ifthen}
\usepackage{amssymb}

\newcommand{\TODO}[1]{\textbf{TODO:} \emph{#1} }
\newcommand{\NOTE}[1]{\textbf{NOTE:} \emph{#1} }
% Uncomment the following lines to remove TODO and NOTE labels
%\renewcommand{\TODO}[1]{}
%\renewcommand{\NOTE}[1]{}

\def\genom{G\textsuperscript{en}oM~}

% proof-reading
\usepackage{xcolor}
\usepackage[normalem]{ulem}
\newcommand{\ra}{$\rightarrow$}
\newcommand{\ugh}[1]{\textcolor{red}{\uwave{#1}}} % please rephrase
\newcommand{\ins}[1]{\textcolor{blue}{\uline{#1}}} % please insert
\newcommand{\del}[1]{\textcolor{red}{\sout{#1}}} % please delete
\newcommand{\chg}[2]{\textcolor{red}{\sout{#1}}{\ra}\textcolor{blue}{\uline{#2}}} % please change
\newcommand{\chk}[1]{\textcolor{ForestGreen}{#1}} % changed, please check

% comments \nb{label}{color}{text}
\newboolean{showcomments}
\setboolean{showcomments}{true} % put to false for the final version
\ifthenelse{\boolean{showcomments}}
	{\newcommand{\nb}[3]{
		{\colorbox{#2}{\bfseries\sffamily\scriptsize\textcolor{white}{#1}}}
		{\textcolor{#2}{\sf\small$\blacktriangleright$\textit{#3}$\blacktriangleleft$}}}
	 \newcommand{\version}{\emph{\scriptsize$-$Id$-$}}}
	{\newcommand{\nb}[3]{}
	 \newcommand{\version}{}}
\newcommand{\pierrick}[1]{\nb{Pierrick}{green}{#1}}
\newcommand{\serge}[1]{\nb{Serge}{blue}{#1}}
\newcommand{\gilberto}[1]{\nb{Gilberto}{red}{#1}}

\lstset{language=Python, basicstyle=\scriptsize, tabsize=4}

\title{\LARGE \bf Simulating complex robotic scenarios with MORSE}
%\title{\LARGE \bf Robotics Simulation Driven by Projects Using MORSE}
%\title{\LARGE \bf Versatile Robotics Simulation Using MORSE}
%\title{\LARGE \bf Evaluation of Robotics Software Using the MORSE Simulator}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Standard author list
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\author[1]{Gilberto Echeverria \thanks{gechever@laas.fr}}
%\author[1]{S{\'e}verin Lemaignan \thanks{slemaign@laas.fr}}
%\author[1]{Arnaud Degroote \thanks{adegroot@laas.fr}}
%\author[2]{Michael Karg\thanks{kargm@in.tum.de}}
%\author[3]{Pierrick Koch\thanks{pierrick.koch@unicaen.fr}}
%\author[4]{Charles Lesire-Cabaniols\thanks{charles.lesire@onera.fr}}
%\affil[1]{LAAS-CNRS, Toulouse, France}
%\affil[2]{TUM, Munich, Germany}
%\affil[3]{GREYC-CNRS, Caen, France}
%\affil[4]{ONERA, Toulouse, France}
%
%\renewcommand\Authands{ and }

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% LLNCS author list
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\author{Gilberto Echeverria\inst{1}\thanks{\email{gechever@laas.fr}}
    \and S{\'e}verin Lemaignan\inst{1,2}\thanks{\email{slemaign@laas.fr}}
    \and Arnaud Degroote\inst{1}\thanks{\email{adegroot@laas.fr}}
    \and Simon Lacroix\inst{1}\thanks{\email{slacroix@laas.fr}}
    \and Michael Karg\inst{2}\thanks{\email{kargm@in.tum.de}}
    \and Pierrick Koch\inst{3}\thanks{\email{pierrick.koch@unicaen.fr}}
    \and Charles Lesire\inst{4}\thanks{\email{charles.lesire@onera.fr}}
    \and Serge Stinckwich\inst{3,5}\thanks{\email{serge.stinckwich@ird.fr}}
}

\institute{
    CNRS, LAAS, 7 avenue du colonel Roche, F-31077 Toulouse, France
    / Universit{\'e} de Toulouse, UPS, INSA, INP, ISAE, LAAS,
    F-31077 Toulouse, France
    \and
    Institute for Advanced Studies, Technische Universit\"{a}t M\"{u}nchen,
    D-85748 Garching, Germany
    \and
    UMR 6072 GREYC Universit{\'e} de Caen-Basse Normandie/CNRS/ENSICAEN, France
    \and
    ONERA -- the French Aerospace Lab, F-31055, Toulouse, France
    \and
    UMI 209 UMMISCO\\IRD/IFI/Vietnam National University, Vietnam
}

\begin{document}
\maketitle

\begin{abstract}
  MORSE is a robotic simulation software developed by roboticists from several
  research laboratories. It is a framework to evaluate robotic algorithms and
  their integration in complex environments, modeled with the Blender 3D
  real-time engine which brings realistic rendering and physics simulation. The
  simulations can be specified at various levels of abstraction. This enables
  researchers to focus on their field of interest, that can range from
  processing low-level sensor data to the integration of a complete
  team of robots. After nearly three years of development, MORSE is a mature
  tool with a large collection of components, that provides many innovative
  features: software-in-the-loop connectivity, multiple middleware support,
  configurable components, varying levels of simulation abstraction,
  distributed implementation for large scale multi-robot simulations and a
  human avatar that can interact with robots in virtual environments. This
  paper presents the current state of MORSE, highlighting its unique features
  in use cases.
\end{abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
\label{section:introduction}

Simulations are an essential component in robotics research, allowing the
evaluation and validation of many sorts of developments before their integration
on-board real robots.  For such validations to be useful, the simulation must
provide enough fidelity with respect to the real world, within the requirements
of the considered robotics application. Creating a fully realistic simulation in
every aspect remains nearly impossible and sometimes can also be seen
as an inconvenience. Therefore numerous simulators are
focused on a given specific aspect ({\em e.g.} terramechanics to study
locomotion, contact forces to study manipulation, realistic photo-rendering to
study vision algorithms, ...).

The MORSE simulator presented here is not targeted to the study of a specific
domain of robotics, but is rather meant as a tool that can be used to test and
evaluate {\em integrated robot software}, {\em i.e.} the suite of processes required to
autonomously achieve complex missions. Using Blender to simulate photo-realistic
3D worlds and the associated physics engine, it brings enough realism to evaluate
complete sets of software components within a wide range of application contexts.

%\NOTE{Simon finds the intro too poor as it is now: here one or two short
  %paragraphs tha highlight the specificities of Morse should be written.}

The simulator is designed to be useful under varied environments, and provides
features to adapt itself to existing robotic architectures, without imposing
any changes on them to connect with MORSE. It has modular components
that are versatile and configurable, to permit \emph{software-in-the-loop}
testing of robotics software.
Input from several researchers has guided the evolution of this tool to satisfy
the requirements of different labs, while keeping to its design principles.
MORSE works on all major software platforms: win32, Linux and OS X. It is
developed as an open--source project with a BSD 3-clause license.
\footnote{User documentation and additional information are available at
\url{http://morse.openrobots.org}, and the source code can be downloaded from
\url{http://github.com/laas/morse.git}.} 

The outline of this paper is as follows: Section~\ref{section:othersims} reviews
other comparable robotics simulators, and Section~\ref{section:overview}
introduces the main design principles of MORSE. Section~\ref{section:features}
is the heart part of the article: it depicts the main features of MORSE, each
being exemplified with the projects for which they were developed. Finally
Section~\ref{section:discussion} gives the conclusion and future plans for the
simulator.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related Work}
\label{section:othersims}

The Player/Stage/Gazebo\cite{psg-1232} is a well known robotics suite.
It is a full set of tools that include the Player communication layer
and two integrated simulators: Stage \cite{Gerkey03theplayer/stage} is basically a
2D simulator optimized for navigation on flat and closed environments.
One of its advantages is the capability to handle very large numbers of
simplified robots \cite{springerlink:10.1007/s11721-008-0014-4}. However, it is
not ideal for more complex scenarios, specially in 3D space. The more recent
Gazebo \cite{Koenig04designand} was developed to cover these shortcomings.
It has received an important boost in its development with its integration
into the ROS platform, and has thus become the most commonly used robotics
simulator. It integrates very well with ROS and Player, but connectivity with
other middlewares requires additional programming.

The Unified System for Automation and Robot Simulation (USARSim)\cite{usarsim-4209284} shares many design concepts with MORSE. It
was initially developed as a simulator for search and rescue operations, uses
the Unreal Engine gaming platform and is built with the concept of modular
components. It is widely used as an evaluation tool for the well known RoboCup
competitions. However, it uses an adhoc interface to communicate with external
software and does not support some of the most common robotics
middlewares. The Unreal Development Kit (UDK) used is a closed-source library and is not
available on every platform.

Webots \cite{Webots04} is a popular commercial simulator.
It provides a full programming environment to create
customized robots and environments, but the interface to construct new
components and robots is unintuitive and complex, requiring searching trough
data trees to adjust physical and geometrical parameters.
It also has an integrated code editor, but the control programs created in it
must later be converted and transferred to the final robot platform.

Another commercial simulator is V-REP \cite{Freese:2010:VRE:1947545.1947555},
with a large variety of components and sensors available. It allows
scripting of the components using the LUA language. Being modular, it
allows for copy-and-paste functionality of the components. However, it
provides no native method for communication with middlewares; such
functionality must be provided by the user in the form of add-ons.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{MORSE Architecture Overview}
\label{section:overview}

The Modular Open Robots Simulation Engine (MORSE) is a library of Python
scripts that run on the Blender Game Engine (BGE) to interface a 3D virtual
environment with external robotics software. Its main design principles have
been described in \cite{5980252}, they are quickly recalled here.
%Objects in the BGE can be completely configured, from physics properties (like
%mass, friction coefficients and collision bounding boxes) to event and
%behavior scripts using Python.

The BGE is used as the base platform for the graphical display of the simulated
world and the physics simulation, using the Bullet physics library.
The simulation is organized as a main core of control functionality that initializes
and coordinates the events in the BGE, and a collection of components that
can be used to assemble a robot with sensors and actuators.
A variety of communication tools allow each of the MORSE components to connect
with external robotics software through middlewares.
MORSE has support for some of the most commonly used robotics
middlewares nowadays, including ROS \cite{ros-288}, Pocolibs
\cite{Pocolibs|web} and YARP \cite{metta|ars06}.
Other middlewares are regularly being added, mainly driven by the needs of new
users. This process is simple, as existing middleware bindings can be used as
templates for the new ones.

%MORSE aims to provide a simulation where complex robots can fully
%carry out missions in large scale environments.
%It does not intend to achieve super realistic simulation of each individual
%component, but a useful approximation of the behavior of the whole ensemble.
MORSE sensors and actuators are minimalistic in their functionality and completely
middleware agnostic. They can provide similar data as their real
world counterparts, but some of them have multiple variants that can work
at different levels of realism and abstraction.
The data employed by the components can be altered through the use of
components called \emph{modifiers}. These add noise or change the data as
required to better match the data with real sensors/actuators (for instance,
transforming the coordinate frame used by Blender into the Universal Transverse
Mercator coordinate system, or adding noise to images captured by Blender cameras).
When a simulation scene is created, the components are linked to middlewares as
specified in a configuration script, and the necessary functionality is added
to the components to be able to transmit/receive data through the middleware as
data streams or synchronous/asynchronous requests.
The whole data flow in MORSE can be seen in the diagram of
Fig.~\ref{fig:dataflow}.

\begin{figure}[ht!]
\centering
    \includegraphics[width=0.7\textwidth]{pics/simulation_main_loop-may2012.png}
\caption{Overview of the data flow in MORSE, between the simulated world
    in Blender and the external robotics software}
\label{fig:dataflow}
\end{figure}

%\serge{Remove trailing local\_data in the picture ?}

MORSE can be easily extended by adding new components that inherit from the
existing base classes. All components are programmed in Python, since this is
the language that Blender uses for its scripts. However, when coding components
that require a faster processing time, they can be implemented in C/C++ and
interfaced with Python using Swig.

%MORSE time management must be consistent with the execution
%logic in the BGE. Python scripts in BGE are executed at a constant
%frequency, which is 60 Hz by default in Blender. MORSE components have to
%respect this base frequency or run at lower speeds, but not higher. However,
%the global frequency in Blender can be increased from the MORSE configuration
%scripts.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Morse Main Features}
\label{section:features}


%-----------------------------------------------%
\subsection{Blender Integration}
\label{section:blender}

Being based on the Blender 3D \cite{blender|web} modeling software, any
object, robot or environment can be created and immediately be made ready
to use in MORSE.
Many file formats for 3D models can be imported directly into Blender, further
increasing the range of elements that can be used.
The high level of graphical detail is specially useful for realistic looking
simulations, and very important when doing image processing from simulated
video cameras.
It is convenient to have simulation environments recreating the terrain and
buildings of real experimentation sites.
Transforming the 2D map of a building into a 3D model is straightforward in
Blender. However, outdoor terrains for experiments in \emph{field robotics} are
more difficult to create by hand.
We have developed additional plug-ins for Blender that read Digital Elevation
Map (DEM) files and create the appropriate 3D meshes. Adding normal maps and
aerial photography for textures creates very realistic simulated
environments. Figure~\ref{fig:models} shows the modeling  
capabilities of Blender exploited in MORSE to create robots and 
environments from DEM data.

\begin{figure}[ht!]
\centering
\begin{tabular}{cc}
 \includegraphics[height=1.55in]{pics/MORSE-rmax_mesh.png} &
 \includegraphics[height=1.55in]{pics/MORSE-quarry_ok-1.png}
\end{tabular}
\caption{Left: Modeling of an R-Max robotic helicopter. Right: Robots on a
    terrain imported from a Digital Elevation Map; the view from a camera mounted
    on a helicopter robot is shown in the top right frame}
\label{fig:models}
\end{figure}


%-----------------------------------------------%
\subsection{Component Library and Scene Construction}
\label{section:components}

MORSE provides a collection of components that can be used to construct robots
with various configurations.
\emph{Sensors} recover data from the simulated world and store it. This is
done using the Blender predefined interfaces for the BGE and Python scripts.
For example, GPS read the absolute coordinates of the sensor in the
Blender world, laser scanners use ray tracing operations of z-buffers to
generate range images and cameras use renders from the perspective of the
Blender camera to produce images. Parameters that determine how the sensors
gather data can be adjusted, such as range, resolution, image sizes, etc.

\emph{Actuators} carry out actions within the simulated
world. They provide motion to the robots through several
methods and algorithms, or control moving parts such as robotic arms or
pan-tilt units. In most cases, the motions are implemented using the
functions in Blender to add a certain linear and angular speed to an
object.
Robotic arms consist of a series of articulated segments, and use the
Blender armature system to determine the degrees of freedom at each joint.
They can be operated either by direct control of the angles at each joint
or by control of the end effector with Inverse Kinematics (using iTaSC
\cite{iTaSC}, a constraints-based IK solver available for the BGE).

\emph{Robots} are the platform upon which all sensors and actuators must be mounted in
order to function. They currently have no behavior of their own, but define the
physical shape and properties like mass, friction and collision bounds
used by the Bullet physics library to compute the interactions with
the environment.

The component library also includes other objects that can be used in the
simulation, from large outdoor environments, to furniture and small items.
All of these can be imported from individual Blender files into a simulation
scenario.

Building and configuration of scenarios are done with a set of Python
classes provided by MORSE, known as the \emph{Builder API}. 
The Builder API provides an internal domain-specific language (DSL) that completely
hides the somewhat complex interface of Blender from the user, so that those
unfamiliar with Blender can directly configure MORSE using Python scripts.
Scripts can then be tracked on a version control system to follow changes and
apply patches.
The API offers classes to add robots, sensors and actuators, to position,
rename and configure any of the parameters used by these components, to
include additional objects (furniture, obstacles, etc.) and to add middleware
bindings, modifiers and services for each component.

%-----------------------------------------------%
\subsection{Adjustable Levels of Realism}
\label{section:realism}

Many components come in several versions, which produce more or less
realistic behavior, and can be chosen depending on the objective of the
simulation and processing that will be applied to the data.

Ground robots can consist of rigid bodies for chassis and wheels using physical
constraints to give realistic movement based on the speeds of the
wheels. Alternatively, some robots are handled as a single rigid box sliding
over the ground when the details of the motion of the robot are not
important. For aerial and submarine robots the physics are limited to collision
detection, but they are not affected by gravity, and there is no simulation of
air or wind currents -- but external dynamic models can be linked to MORSE for
such purposes. The associated actuators offer the choice between controlling
the speeds of wheels independently, controlling the motion of a robot as a whole
with linear and angular velocities, giving direct waypoint coordinates for
destination or ``teleporting'' a robot to a desired location.

Some sensors provide almost identical raw data as their real counterparts,
which can then be processed to extract relevant information,
and later used to make decisions. When the processing of data is not of
interest to the experiment, alternative sensors can be used that provide
higher level data, extracted directly from the BGE scenario, and avoid costly
processing.
The clearest example of this are the cameras: the regular video camera
generates renders of the Blender scene, and outputs images to be processed by
software. This generates much data, and can slow down the simulation when
rendering for several cameras at once. A new sensor called the \emph{semantic
camera} uses Blender functions to determine the names and global 3D position of
the objects within the view frustum of the camera. It directly outputs this
data, making the simulation of object detection faster and
avoiding the use of image processing algorithms.

%This flexibility permits scientists to focus on specific problems, by 
%simplifying some tasks and isolating the algorithms of interest.
As a practical example, researchers from ONERA use MORSE to evaluate online probabilistic
decision-making on an autonomous UAV. In a first scenario~\cite{teichteil2011},
MDP-based policy optimization allows the UAV to find a suitable zone for an
emergency landing. MORSE video camera sensors are used to feed the raw image data
into the land mapping algorithm.
On a second scenario~\cite{carvalho2012}, a POMDP model is used to optimize the
probability to track and intercept an identified target among others. As the
objective is to evaluate the optimized strategy, processing
simulated images is not necessary. Hence, instead of using a video camera
sensor, the \emph{semantic camera} is used to identify the location of the target,
adding some errors with modifiers to simulate both the sensor and the detection
and identification processes.
%\serge{Too much and here ...}
%\gilberto{Didn't understand your comment}

%\serge{Semantic Camera and Components overlays should be emphasized as
%  two new mechanisms of MORSE. Could we add more information on how
%  Semantic Camera works ?}
%
%\serge{Regarding the adjustable level of realism, you should talk
%  about the SEGWAY model available now in MORSE, as an example of a
%  very accurate physical model compared to the basic ones.}

%-----------------------------------------------%

\subsection{Middleware Configurations}
\label{section:middlewares}

Research laboratories use different middlewares to connect the processes within their
robots. In order to be usable with any architecture, MORSE enforces a
clear separation between components and middlewares. When a simulation is started,
the bindings between sensors/actuators and middlewares are read from the
configuration script, and it is only then that components acquire the functions
necessary to communicate with the outside world.
This separation means that any middleware can be integrated with MORSE, by
simply providing the scripts to marshal MORSE data in the expected format.
Middlewares currently supported include ROS, MOOS, Pocolibs, YARP and
raw TCP/IP sockets.
Information exchange between the simulator and the robotics software can be
done by a constant data stream, or via request/reply interfaces.

MORSE permits using different middlewares within a single simulation
scenario with heterogeneous systems. This is exemplified in the \emph{Action
project} \cite{6106782} developed by the LAAS and ONERA labs.
It consists in the cooperation of ground and air robots to patrol a zone,
locate and follow moving targets.
Each lab provides an existing robotics platform with two different
architectures: LAAS employs Segway RMP 400 land robots, using the \genom
\cite{MALLET-2011-599677} architecture, while ONERA works with Yamaha R-Max
helicopters based on OROCOS \cite{orocos2003}. The simulation uses Pocolibs to
communicate with \genom, and YARP to talk with OROCOS.

%The use of simulation is particularly beneficial for this project, since the trials
%are done in a very specific environments, and require transporting the robots a
%considerable distance, always being dependent on the prevailing weather.
%Software evaluation can be done in MORSE regardless of the weather, and not
%having to plan long trips to the actual experimental site.
%Simulation also simplifies the execution of test runs, since they can be
%restarted from the initial point within seconds.  Future stages of the project
%require the coordination of larger teams of heterogeneous robots. The physical
%robots required for these stages are not currently available, but simulation
%permits for testing of these scenarios in advance.

MORSE has been chosen as the simulator platform for a French research
robotic project called \emph{ANR-PROTEUS}, thanks to
%\gilberto{Removed footnote with PROTEUS website, since it is given in the acknowledgments}
its middlewares versatility and the facility to integrate it with
existing architectures.
The PROTEUS project supports a model-driven engineering approach based on a
domain-specific language and a robotic ontology \cite{Dhouib:2011zr} and aims at
providing a toolchain for robotic development from modeling to software
simulation and deployment on real robots. PROTEUS is based on open-source
softwares like the Eclipse Modeling Project, the ROS middleware and MORSE
simulator. Several robot models are currently under construction (Wifibot,
ECA Camelon, and Thales R-Trooper).
%\gilberto{These would need references, but there is no space left}

%-----------------------------------------------%
\subsection{Component Overlays for Specific Software Architectures}
\label{section:overlays}

%\serge{What is architecture here ? Existing software architecture,
%  hardware ?}
%\serge{Component overlays could be seen as an implementation of the
%  adapter Pattern: \url{https://en.wikipedia.org/wiki/Adapter_pattern}}

Besides the components and middlewares available, it is
further possible to adapt these elements to better fit an existing
architecture and allow true \emph{software-in-the-loop} functionality.
MORSE components provide dedicated I/O interfaces. In
many cases, the interface methods will not be the same as those used in an
actual device, although the component has the same functionality.
For instance, an actuator may have two separate functions to modify its linear
and angular velocities, while the corresponding MORSE component uses only one
function with the two parameters.

To avoid creating additional components,
MORSE implements the notion of \emph{component overlays}. Following
the well-known adapter pattern, they are implemented as
special components that override (or wrap) the default
behavior to make it match a different architecture.
In the case of middlewares, it is possible to either use the default
serialization methods provided by MORSE, or write additional serialization
functions as extra scripts, specific for single components.
Overlays are implemented as Python scripts that provide an interface between
the real component being simulated and the equivalent sensor available in
MORSE.
These features have been used to connect MORSE with an existing
Unmanned Aerial Vehicle (AUV) control architecture~\cite{barbier2011}
without modifying the code in either the original architecture or MORSE.
%Overlaying the components and middleware serializations yields these results:
%\begin{itemize}
%  \item the middleware used is based on sockets; while the default MORSE socket
%    middleware serializes the component data one after the other, it has been
%    possible to match the quite complex protocol used in~\cite{barbier2011} by
%    providing custom functions in Python
%  \item the control of the robot is done by providing waypoints to actuators; a
%    specific mechanism that consists in following a path defined by two 3D
%    points, has been obtained by overlaying the default waypoint actuator of
%    MORSE, without having to code any interface component between MORSE and
%    our architecture.
%\end{itemize}


%-----------------------------------------------%
\subsection{Multi-node and Hybrid Simulation}
\label{section:multinode}

%\serge{There is no reference to HLA here. I think this is a major
%  advance that should be cited appropriately.}
The simulation of multiple robots in the complex environments permitted by
MORSE is very demanding on computational and graphics resources.
A scenario with several robots equipped with video cameras and
other sensors, plus the robotics software all running on the same computer will
slow down the system considerably. MORSE offers the possibility of running
multiple instances of the same simulation scenario in separate computers,
coordinated by a central server program, called the \emph{multi-node
manager}. This manager has been implemented using TCP/IP socket communication,
and also using High Level Architecture (HLA) \cite{Kuhl:1999:CCS:318931} for
more strict time management.
While every node shows all of the robots, each node will only
be in charge of controlling a limited number of them. The movements
of robots and specific objects in one node are sent to the multi-node
manager, which in turn collects the updated positions across all nodes
and redistributes the information, so that all nodes can immediately
reflect the changes. The multi-node server also 
synchronizes the time and events across all nodes. This can be used
to slow down the simulation in all nodes, by making them wait for the
synchronization message. However, at the current time it is not possible to
accelerate the simulation speed from the multi-node server.
%\serge{How you could accelerate the time without compromising the quality ?}
%\gilberto{Proposed a way to do it in the Future work section}

This functionality was developed for applications that require a large amount
of robots. Our use case is the rescue robotics project \emph{Rosace}
\cite{springerlink:10.1007/978-3-642-28786-2_32}.
%\cite{springerlink:10.1007/978-3-642-12384-9_18,springerlink:10.1007/978-3-642-28786-2_32}.
Its main objective is the coordination of robotic agents in search and rescue
operations in the case of a disaster. In this scenario, terrestrial robots must
be able to locate human victims, provide support for the victims and avoid
dangerous areas. The robots in the team are to be equipped with different
payloads, and take autonomous decisions on which of them should perform
different tasks in the mission, such as searching, providing a communications
relay, and helping victims directly.
For this project, two or three robots can be handled by a single simulation
node, and synchronized with those in other nodes.  Special sensors in MORSE are
used to determine the distance and visibility between robots, and this
information is used to simulate loss of connectivity between them.
The victims to be saved are internally considered as robots with scripted
behavior, so that their status and position is also synchronized by the
multi-node manager.

Additionally, the multi-node system permits the deployment of hybrid
simulations. A 3D environment that closely represents the real experimentation
site is used. Real robots report their updated positions to the multi-node
server, which reflects the changes on a dummy robot 
in the simulation, so that other simulated robots can see it and interact with it.
In the Action project, a real ground robot moves around while the simulated
helicopter can follow it using video cameras.
The robots communicate in the same way in full simulation or in
real life. The use of HLA makes it possible to synchronize the heterogeneous
systems in both the simulated and the real world. Note however that 
the real robots are not able to ``see'' the simulated ones with their
cameras -- but this could be achieved using an augmented reality scheme that
would modify the data gathered by the real robots.

%-----------------------------------------------%
\subsection{The Human Avatar}
\label{section:human}

For human-robot-interaction scenarios, we require a way to combine the
reactive and sometimes unpredictable behavior of a human interacting with its
environment with a simulated robot. Therefore the human avatar of the MORSE
simulator has been equipped with an intuitive control that enables users to act
upon the simulated environment. Inspired by modern 3D-computer games, the user
takes a third-person perspective behind the human avatar to move around as
shown in Fig.~\ref{fig:human_control} (left).
While moving around, the camera tries to avoid the objects and walls placed
between the camera and the human avatar to prevent occlusions.  All objects
that can be interacted with can be displayed by pressing a key on the
keyboard (also illustrated in Fig.~\ref{fig:human_control}). When the user
decides to interact with an object, the camera switches to a first-person
perspective and offers an interface showing possible actions the
user can take when pointing to specific objects, as shown in Fig.~
\ref{fig:human_control} (right). Those actions at the moment include
picking up and releasing objects, opening and closing drawers and cupboards and
switching on and off specific objects like a light or an oven.

\begin{figure}[ht!]
\centering
\begin{tabular}{cc}
 \includegraphics[width=0.475\textwidth]{pics/human_control_1.png} &
 \includegraphics[width=0.475\textwidth]{pics/human_control_2.png}
\end{tabular}
\caption{Left: third-person view of the human component that is used to
    navigate in the environment, displaying the names of objects that the human
    can interact with. Right: first-person perspective of the human avatar that
    indicates a possible ``pick-up-action'' with the bread.}
\label{fig:human_control}
\end{figure}

The motions of the avatar are animated using Blender %functionality such as
armatures, inverse kinematics, and predefined movement loops.
The avatar can be controlled much like a character in a videogame, using either
the mouse and keyboard or a combination of the Microsoft Kinect and the
Nintendo Wiimote. This enables users to perform
pick and place actions in simulated worlds while at the same time the
simulated robot(s) can be controlled through the supported robotic middlewares.

% TODO: Add picture of kinect/wiimote control

The human avatar is meant to be used in \emph{personal robotics} scenarios.
In these, complex robots are expected to collaborate with humans to carry out
ordinary household tasks, such as cleaning, serving food or aiding humans to
navigate an environment.
Robots used in these experiments are equipped with one or two arms, and are
capable of grasping objects. They are also expected to react to the actions of
their human collaborator, using video cameras, motion detectors or telemetry to
determine the location, pose and attitude of the human.
This can be done at two different levels of
abstraction. Using the video cameras to recognize the human and its pose can be
done realistically, with the associated computational cost and uncertainties.
Alternatively, the avatar can directly export the position of all of its
joints, and feed them back to the robot, simulating a full motion capture
system and avoiding the processing costs.

An example use case in this scenario is the testing and validation of human-aware
navigation planners of service robots in human-centered environments at TU Munich.
In this case, a simulated human tracking system provides the human pose to the
robot while the robot navigates in the environment in a way that is safe and
legible for the human \cite{kruse10exploiting}. In this project, MORSE has not only been used as a
powerful tool for testing human-aware navigation strategies before carrying out
experiments with real humans: it has also been used to evaluate them as
Lichtenth{\"a}ler et al. show in \cite{lichtenthaeler2012increasing} by
video-based user studies. After successful testing and evaluation, the
human-aware navigation was applied using real robots and humans resulting in
a safe and reliable behavior of the robot.

%In another project at TU Munich, a simulated kitchen environment is used
%to test and evaluate a plan recognition and monitoring system using the
%semantic camera of MORSE as a simulated object recognition system with
%a reactive robot control system.
% \serge{A missing reference ?} Unfortunately there is no publication about this 
% project yet... 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary and Future Work}
\label{section:discussion}

We have presented the main features developed within the MORSE simulator,
following the requirements of a variety of projects in robotics research.
The design and architecture of MORSE has proved to be flexible and powerful
enough to allow researchers to use it under various circumstances to test their
robotics algorithms. Users can customize the existing components according to
their needs, or develop new ones when necessary, by describing their behavior
in Python scripts.
%\serge{Why the dev process is simple ?}
All new developments done on top of MORSE are made available to the whole
community, thanks to the open source license of the simulator.

MORSE allows for quick integration with an existing architecture (multiple
middlewares, modular components and component overlays), heterogeneous robots
(mixing components and middlewares), multiple robot simulation (multi-node
synchronization) and human-robot interaction (high abstraction level sensors
and human avatar).

Further work is planned to increase the usefulness of MORSE:
for human-robot-interaction experiments, it is ideal to have a deeper
immersion when using the human avatar.  A planned feature is to provide stereo
images of the simulation to the user wearing special goggles. This can trivially
be done
from Blender, with some separation of the images produced for the two eyes.
Increased integration with motion reading devices, such as Microsoft Kinect can
also make the experience more natural, by allowing a finer control over the
human avatar.
Another planned work is to be able to couple MORSE simulations with
other physical simulation engines thanks to the HLA support.
Further development is also necessary to give users more control over the speed
of the simulation, by adjusting the base execution frequency of the BGE.

\subsubsection*{Acknowledgments}
This work has been partially supported by the DGA funded Action project
(\url{http://action.onera.fr}), the STAE foundation Rosace project
(\url{http://www.fondation-stae.net}) and the ANR-PROTEUS
project (\url{http://anr-proteus.fr/})

% ---- Bibliography ----
\bibliographystyle{ieeetr}
%\bibliographystyle{unsrt}
% \bibliographystyle{splncs03}
\bibliography{./morseBiblio,charles}
\end{document}
